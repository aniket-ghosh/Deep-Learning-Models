{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob as glob\n",
    "import cv2\n",
    "import random\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_dataset(directory,size,img_type,seed,split,trainfile_name,testfile_name):\n",
    "    \n",
    "    cache = []\n",
    "    labels = []\n",
    "    folders = glob.glob(directory+\"\\*\") #going into the folder containing the sub-folders of images\n",
    "    y =-1\n",
    "    \n",
    "    for folder in folders: #iterating through each folder at a time\n",
    "        y =y+1           \n",
    "        for file in glob.glob(folder+'\\*.'+img_type): #iterating through each image in the sub-folder\n",
    "            img = cv2.imread(file)                    #reading each image\n",
    "            img = cv2.resize(img,(size,size))         #resizing each image\n",
    "            cache.append(img)\n",
    "            labels.append(y)\n",
    "    \n",
    "    print(\"Reading of images done\")\n",
    "    #shuffling the image-array and labels together\n",
    "    \n",
    "    random.seed(seed)\n",
    "    temp = list(zip(cache,labels))\n",
    "    random.shuffle(temp)\n",
    "    data,label = zip(*temp)\n",
    "    \n",
    "    #splitting the images and labels into train and test data\n",
    "    \n",
    "    m = len(cache)\n",
    "    z = int(np.round_((m*split)))\n",
    "    \n",
    "    X_train = data[:z]\n",
    "    Y_train = label[:z]\n",
    "    \n",
    "    X_test = data[z:]\n",
    "    Y_test = label[z:]\n",
    "    \n",
    "    X_train=np.stack(X_train,axis=0)\n",
    "    Y_train=np.array(Y_train)\n",
    "    X_test=np.stack(X_test,axis=0)\n",
    "    Y_test=np.array(Y_test)\n",
    "    \n",
    "    #creating h5py files \n",
    "    hf = h5py.File(trainfile_name,'w')\n",
    "    hf.create_dataset(\"X_train\",data=X_train)\n",
    "    hf.create_dataset(\"Y_train\",data=Y_train)\n",
    "    hf.close()\n",
    "    \n",
    "    hf = h5py.File(testfile_name,'w')\n",
    "    hf.create_dataset(\"X_test\",data=X_test)\n",
    "    hf.create_dataset(\"Y_test\",data=Y_test)\n",
    "    hf.close()\n",
    "    \n",
    "    print(\"Files have been created\",\"\\n\")\n",
    "    print(\"The shapes are as follows\",X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading of images done\n",
      "Files have been created (19291, 80, 80, 3) (19291,) (8267, 80, 80, 3) (8267,)\n"
     ]
    }
   ],
   "source": [
    "creating_dataset(directory=\"Malaria_cell_images\",size=80,img_type=\"png\",seed=2,split=0.7,trainfile_name=\"Train_Malaria.h5\",testfile_name=\"Test_Malaria.h5\")\n",
    "                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
